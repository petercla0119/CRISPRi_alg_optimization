{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"aJHaSsYfczA8"},"source":["# dual guide parser - August 2021\n"," - **Project:** iNDI.\n"," - **Author(s):** Dan Ramos, Lirong Peng, Faraz Faghri and Mike Nalls \n","\n","---\n","### Quick Description: \n","- **Problem:** We need a method that preprocesses guides for experiments, something that parses fastqs to only include those guides included in R1 and R1 from the concensus guide list ... we also need to catalogue failed reads. We also need this to take MiSeq and other data.\n","- **Solution:** The workflow below sums it up pretty well. Let's test out some code on small iNDI datasets provided by Dan R. We have added support from SeqIO \n","\n","### Workflow:\n","0.   Set up notebook.\n","1.   Import data, this includes concensus guides and R1 + R2 fastqs.\n","2.   Identify matching read groups across R1 and R2.\n","3.   Reduce the datasets to the read groups that match in R1 and R2.\n","4.   Split into 'hits.\\*'  and 'recombinants.\\*'.  \n","'hits.\\*' denotes read group matches and the protospacers match.\n","'recombinants.\\*' denotes read group matches but one or more protospacers does not.\n","5.   Export 'hits.\\*' and 'recombinants.\\*' per fastq.\n","\n","### Notes on data for testing:\n","- **20200513_library_1_2_unbalanced_dJR051.csv** = All elements of the dual sgRNA library. Sequence from protospacer_A and protospacer_B columns must be present in the same row to be considered a match.  \n","- **UDP0011_S5_R1_001.fastq.gz** = First 20 bases of each read should match \"protospacer_A\" sequence from \"20200513_library_1_2_unbalanced_dJR051.csv\".  \n","- **UDP0011_S5_R2_001.fastq.gz** = First 20 bases of each read should match reverse complement of \"protospacer_B\" sequence from \"20200513_library_1_2_unbalanced_dJR051.csv\".  \n","** The major change in V3 of this code is matching sequences for the guides using all UPPER CASE bases intead of being case-sensitive.\"\n","** V5 skips the first base since it is always G. Essentially running 19bp matches.\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SzcIkfb7fflS"},"source":["# 0.   Set up notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_oAO3BXcqYd","outputId":"d8c19824-dc28-4d83-93a8-10a1208ee636"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (3.6.1)\n","Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from tables) (1.19.5)\n","Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables) (2.7.3)\n","Mounted at /content/drive/\n","/content/drive/Shared drives/CARD_iNDI/scratch/dual_guide_parser\n"]}],"source":["import os\n","# from google.colab import drive\n","import pandas.util.testing as tm\n","import h5py\n","import numpy as np\n","import pandas as pd\n","import math\n","import sys\n","import joblib\n","import subprocess\n","import argparse\n","import gzip\n","import textwrap\n","\n","# !pip install --upgrade tables\n","# ! pip install biopython\n","\n","# import tables\n","\n","import requests\n","from Bio import SeqIO \n","from Bio.Seq import reverse_complement\n","from Bio.SeqIO.QualityIO import FastqGeneralIterator\n","from itertools import islice\n","# Comment out below after testing.\n","\n","# drive.mount('/content/drive/')\n","# os.chdir(\"/content/drive/Shared drives/CARD_iNDI/scratch/dual_guide_parser\")\n","# ! pwd\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"SBy4dwTnpU-1","outputId":"cd310fd4-caf2-4f8f-ab51-8b1c9c22cf2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["##############################################\n","Thanks for trying the dual_guide_parser from CARD + iNDI + DTi.\n","To run this code, you will need to specify the guides_file, this is a file similar to the example 20200513_library_1_2_unbalanced_dJR051.csv.\n","You will need to specify a pair of R1 and R2 files, such as UDP0007_S1_R1_001.fastq.gz and UDP0007_S1_R2_001.fastq.gz.\n","You can also specify the number of read groups you are interested for testing the tool, this relates to the option n_groups. This will only read that many readgroups from the R1 and R2 files, allowing you to speed things up a bit.\n","This code must be run from the working directory that contains the R1 and R2 files, but the guides_file can be anywhere, just specify a full path to the guides file like ~/Desktop/20200513_library_1_2_unbalanced_dJR051.csv.\n","This is best run on a large RAM / high CPU set up as the files are quite large.\n","Finally, to run this code, you will need several packages, including biopython. To see the required packages listed, run with the -h option.\n","##############################################\n"]},{"name":"stderr","output_type":"stream","text":["usage: ipykernel_launcher.py [-h] [--guides_file GUIDES_FILE]\n","                             [--r1_file R1_FILE] [--r2_file R2_FILE]\n","                             [--N_reads N_READS]\n","ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-b6010eba-8738-4fa4-9ee7-973bb74b8ff7.json\n"]},{"ename":"SystemExit","evalue":"ignored","output_type":"error","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}],"source":["# Set  options for testing.\n","\n","# guides_file = \"20200513_library_1_2_unbalanced_dJR051.csv\"\n","# r1_file = \"UDP0011_S5_R1_001.fastq.gz\"\n","# r2_file = \"UDP0011_S5_R2_001.fastq.gz\"\n","# N_rows = 10000 # Speed up testing, this just reads the first 10K sequences.\n","\n","# Set the options for production.\n","\n","parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=textwrap.dedent('''\\\n","\n","Thanks for trying the dual_guide_parser from CARD + iNDI + DTi.\n","To run this code, you will need to specify the guides_file, this is a file similar to the example 20200513_library_1_2_unbalanced_dJR051.csv.\n","You will need to specify a pair of R1 and R2 files, such as UDP0007_S1_R1_001.fastq.gz and UDP0007_S1_R2_001.fastq.gz.\n","You can also specify the number of read groups you are interested for testing the tool, this relates to the option n_groups. \n","This will only read that many readgroups from the R1 and R2 files, allowing you to speed things up a bit.\n","This code must be run from the working directory that contains the R1 and R2 files, but the guides_file can be anywhere, just \n","specify a full path to the guides file like ~/Desktop/20200513_library_1_2_unbalanced_dJR051.csv.\n","This is best run on a large RAM / high CPU set up as the files are quite large.\n","Finally, to run this code, you will need several packages, including biopython. To see the required packages listed, run with the -h option.\n","\n","'''))    \n","parser.add_argument('--packages', help='Request for packages required to run, and how to install.', action='store_true')\n","parser.add_argument('--guides_file', type=str, default='missing', help='Mandatory input filepath. This is a file similar to the example 20200513_library_1_2_unbalanced_dJR051.csv. This can be a complete filepath')\n","parser.add_argument('--r1_file', type=str, default='missing', help='Mandatory input file name. An R1 file in your working directory.')\n","parser.add_argument('--r2_file', type=str, default='missing', help='Mandatory input file name. An R2 file in your working directory.')\n","parser.add_argument('--N_reads', type=int, default=0, help='Optional number of readgroups to test. An integer.')\n","\n","args = parser.parse_args()\n","\n","if(args.packages):\n","  print(\"Must have numpy and pandas available. \\n Additionally, must install biopython.\")\n","  print(\"To install biopython, run pip install biopython, or, if using conda,\")\n","  print(\"conda install -c conda-forge biopython\")\n","  quit()\n"," \n","print(\"#\"*46)\n","print(\"\")\n","print(\"Here is some basic info on the command you are about to run.\")\n","print(\"Python version info...\")\n","print(sys.version)\n","print(\"CLI argument info...\")\n","print(\"The guides file you are using is\", args.guides_file, \".\")\n","print(\"The r1 file you are using is\", args.r1_file, \".\")\n","print(\"The r2 file you are using is\", args.r2_file, \".\")\n","print(\"How many read groups are only for a quick test and not the full set?\", args.N_reads, \".\")\n","print(\"\")\n","print(\"#\"*46)\n","\n","guides_file = args.guides_file\n","r1_file = args.r1_file\n","r2_file = args.r2_file\n","N_reads = args.N_reads\n","N_rows = N_reads"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"zPDLZAtQZRHz","outputId":"d35f4290-81d8-4047-b21a-a10b2c7799bb"},"outputs":[{"ename":"SystemExit","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-969e99e1c2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#parser.add_argument('--packages', help='Request for packages required to run, and how to install.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#if(args.packages):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2515\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2517\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemExit\u001b[0m: 2"]}],"source":["%tb"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YMa7yQTnoc2i"},"source":["# 1. Import data, this includes concensus guides and R1 + R2 fastqs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fsdM_Hmofhh"},"outputs":[],"source":["# Import data to pandas.\n","guides_df = pd.read_csv(guides_file, engine='c')\n","# \n","# # Import R1s and R2s.\n","# ## pysam way Pysam introduces many other file format compatibilities such as \n","# ## CRAM/SAM/BAM\n","# if (N_rows == 0):\n","#   with pysam.FastxFile(r1_file) as fh:\n","#     r1_df = pd.DataFrame([(entry.name, entry.sequence, entry.comment, entry.quality) for entry in fh], columns=['name','seq', 'comment', 'qual'])\n","#   with pysam.FastxFile(r2_file) as fh:\n","#     r2_df = pd.DataFrame([(entry.name, entry.sequence, entry.comment, entry.quality) for entry in fh], columns=['name','seq', 'comment', 'qual'])\n","# else:\n","#   with pysam.FastxFile(r1_file) as fh:\n","#     r1_df = pd.DataFrame([(entry.name, entry.sequence, entry.comment, entry.quality) for entry in islice(fh,0,N_rows)], columns=['name','seq', 'comment', 'qual'])\n","#   with pysam.FastxFile(r2_file) as fh:\n","#     r2_df = pd.DataFrame([(entry.name, entry.sequence, entry.comment, entry.quality) for entry in islice(fh,0,N_rows)], columns=['name','seq', 'comment', 'qual'])\n","# \n","# ## SeqIO way\n","# For more compatitibility with other files types will need to import as SeqIO objects.\n","# Consider the following suggestions if so.\n","# use to_dict for compatibility with more file types and for true dictionary\n","# functionality. If files too big, use .index.\n","# Otherwise, if more memory needed, instantiate as a list\n","with gzip.open(r1_file, mode = 'rt') as r1, gzip.open(r2_file, mode = 'rt') as r2: \n","  r1_it = FastqGeneralIterator(r1)\n","  r2_it = FastqGeneralIterator(r2)\n","\n","  if (N_rows == 0):\n","    r1_df = pd.DataFrame(r1_it, columns=['title', 'seq', 'qual'])\n","    r2_df = pd.DataFrame(r2_it, columns=['title', 'seq', 'qual'])\n","  else:\n","    r1_df = pd.DataFrame(islice(r1_it, 0, N_rows), columns=['title', 'seq', 'qual'])\n","    r2_df = pd.DataFrame(islice(r2_it, 0, N_rows), columns=['title', 'seq', 'qual'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPApu9GX40Ko"},"outputs":[],"source":["# only do this once\n","r1_df.insert(loc=2, column='plus', value='+')\n","r2_df.insert(loc=2, column='plus', value='+')\n","\n","def split_str(s: str) -> str:\n","    return s.split(\" \", maxsplit = 1)[0]\n","r1_df['read_group'] = r1_df[\"title\"].apply(split_str)\n","r2_df['read_group'] = r2_df[\"title\"].apply(split_str)\n","\n","r1_df['title'] = '@' + r1_df['title']\n","r2_df['title'] = '@' + r2_df['title']"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"o495TVBiR9uK"},"source":["This next code block defines the r1 and r2 keys that are 19 BP, also making a reverse complement of r2."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHLG-2tiw0Ff"},"outputs":[],"source":["# New as of v5.\n","\n","guides_df['protospacer_A_19bp_trimmed'] = [x[1:20] for x in guides_df['protospacer_A']]\n","guides_df['protospacer_B_19bp_trimmed'] = [x[1:20] for x in guides_df['protospacer_B']]\n","\n","# Make guide key columns.\n","\n","guides_df['r1_key'] = guides_df['protospacer_A_19bp_trimmed']\n","\n","# R2 is tricky as it is the reverse compliment. Flip it and translate using the function below.\n","\n","guides_df['r2_key'] = guides_df['protospacer_B_19bp_trimmed'].apply(reverse_complement)\n","guides_df['r1_r2_key'] = guides_df['r1_key'] + \"_\" + guides_df['r2_key']"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dCWhqxlOGRxF"},"source":["# 2. Identify matching read groups across R1 and R2."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"joNg3niHGbeN"},"outputs":[],"source":["# Pull the read groups from R1 and R2. Make a concensus read group list.\n","r1_read_groups_df = r1_df[['read_group']]\n","r2_read_groups_df = r2_df[['read_group']]\n","\n","consensus_read_groups_df = r1_read_groups_df.merge(r2_read_groups_df, on ='read_group', how='inner')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZyodSGuK6et","outputId":"d05d00ba-d213-438a-d836-dcfb10684859"},"outputs":[{"name":"stdout","output_type":"stream","text":["##############################################\n","R1 had 10000 potential read groups, of these 100.0 % were among the concensus read groups. R2 had 10000 potential read groups, of these 100.0 % were among the concensus read groups. In total there are 10000 read groups that are matching across R1 and R2 for this experiment.\n","##############################################\n"]}],"source":["# Quantify obvious pair failures.\n","\n","r1_N_attempted_read_groups = r1_df.read_group.shape[0]\n","r2_N_attempted_read_groups = r1_df.read_group.shape[0]\n","consensus_N_read_groups = consensus_read_groups_df.shape[0]\n","r1_pcnt_consensus = (consensus_N_read_groups/r1_N_attempted_read_groups)*100\n","r2_pcnt_consensus = (consensus_N_read_groups/r2_N_attempted_read_groups)*100\n","\n","print(\"#\"*46)\n","print(f\"R1 had {r1_N_attempted_read_groups} potential read groups, of these {r1_pcnt_consensus} % were among the concensus read groups. R2 had {r2_N_attempted_read_groups} potential read groups, of these {r2_pcnt_consensus} % were among the concensus read groups. In total there are {consensus_N_read_groups} read groups that are matching across R1 and R2 for this experiment.\")\n","print(\"#\"*46)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2zOP8eYwMyGT"},"source":["# 3. Reduce the datasets to the read groups that match in R1 and R2.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuYjGWdNM7KJ"},"outputs":[],"source":["# Reduce R1 and R2 to only those in the concensus_read_groups df.\n","\n","consensus_read_list = consensus_read_groups_df.read_group.unique()\n","\n","r1_df['in_consensus'] = r1_df.read_group.isin(consensus_read_list)\n","r2_df['in_consensus'] = r2_df.read_group.isin(consensus_read_list)\n","\n","r1_reduced_df = r1_df[r1_df['in_consensus'] == True]\n","r2_reduced_df = r2_df[r1_df['in_consensus'] == True]\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"p8w5veyMn9mp"},"source":["# 4. Split into 'hits.\\*'  and 'recombinants.\\*'.  \n","'hits.\\*' denotes read group matches and the protospacers match.\n","'recombinants.\\*' denotes read group matches but one or more protospacers does not."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtZ3wOZUn80-"},"outputs":[],"source":["# Get the guide seqs, these relate to the 19 BP segments in the guide_df. Then make its expected complement.\n","\n","r1_reduced_df['guide_seq'] = [x[1:20] for x in r1_reduced_df.seq]\n","r2_reduced_df['guide_seq'] = [x[0:19] for x in r2_reduced_df.seq]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNjS7ou7M-BN","outputId":"05abcc02-bebe-41e2-9c83-74b0137d3fad"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]}],"source":["# Build dataset that is used to check for recombination w/in each read group.\n","\n","r1_guide_read_df = r1_reduced_df[['read_group', 'guide_seq']]\n","r1_guide_read_df.rename(columns={'guide_seq':'r1_guide_seq'}, inplace=True)\n","\n","r2_guide_read_df = r2_reduced_df[['read_group', 'guide_seq']]\n","r2_guide_read_df.rename(columns={'guide_seq':'r2_guide_seq'}, inplace=True)\n","\n","combined_guide_read_df = r1_guide_read_df.merge(r2_guide_read_df, on='read_group', how='inner')\n","combined_guide_read_df['combined_guide_seqs'] = combined_guide_read_df['r1_guide_seq'] + \"_\" + combined_guide_read_df['r2_guide_seq']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"h0io1SpVKUne","outputId":"ce46b757-5fd9-4008-9809-61a27bd50f46"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>read_group</th>\n","      <th>r1_guide_seq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:3043:1000</td>\n","      <td>GCGGCGGCGGAGCCTTCGG</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:3495:1000</td>\n","      <td>CCGGGCGCGACGGTCTCGG</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:8612:1000</td>\n","      <td>GCGAGGGTGGAAGATGCGG</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:13892:1000</td>\n","      <td>AAGCCGGTCAGACAGAGGC</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:14488:1000</td>\n","      <td>ACCCGCGCCGTGGTCCCGG</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:1624:11725</td>\n","      <td>GGCAGAACGCACTGCGAAG</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:1787:11725</td>\n","      <td>GCAGCTCCGAGGTCGGCGG</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:1805:11725</td>\n","      <td>GCAGCTCCGAGGTCGGCGG</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:3052:11725</td>\n","      <td>AGCCAGACTATCTATGTGA</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>A01256:51:HF2GTDRXY:1:2101:4010:11725</td>\n","      <td>CACCGGGAGGGCTACGCGG</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                 read_group         r1_guide_seq\n","0      A01256:51:HF2GTDRXY:1:2101:3043:1000  GCGGCGGCGGAGCCTTCGG\n","1      A01256:51:HF2GTDRXY:1:2101:3495:1000  CCGGGCGCGACGGTCTCGG\n","2      A01256:51:HF2GTDRXY:1:2101:8612:1000  GCGAGGGTGGAAGATGCGG\n","3     A01256:51:HF2GTDRXY:1:2101:13892:1000  AAGCCGGTCAGACAGAGGC\n","4     A01256:51:HF2GTDRXY:1:2101:14488:1000  ACCCGCGCCGTGGTCCCGG\n","...                                     ...                  ...\n","9995  A01256:51:HF2GTDRXY:1:2101:1624:11725  GGCAGAACGCACTGCGAAG\n","9996  A01256:51:HF2GTDRXY:1:2101:1787:11725  GCAGCTCCGAGGTCGGCGG\n","9997  A01256:51:HF2GTDRXY:1:2101:1805:11725  GCAGCTCCGAGGTCGGCGG\n","9998  A01256:51:HF2GTDRXY:1:2101:3052:11725  AGCCAGACTATCTATGTGA\n","9999  A01256:51:HF2GTDRXY:1:2101:4010:11725  CACCGGGAGGGCTACGCGG\n","\n","[10000 rows x 2 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["r1_guide_read_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yry56iSYn84e","outputId":"7ef94170-23b2-4113-a9d7-b2aec9c36773"},"outputs":[{"name":"stdout","output_type":"stream","text":["##############################################\n","There are a total of 10000 potential read groups after filtering, of these 62.370000000000005 % were on target for R1 and R2. This means 37.63 % are recombinant read groups.\n","##############################################\n"]}],"source":["# Flag expected pairs from the guides_df.\n","\n","reference_list = guides_df['r1_r2_key'].tolist()\n","uppercase_reference_list = [x.upper() for x in reference_list]\n","\n","combined_guide_read_df['uppercase_combined_guide_seqs'] = combined_guide_read_df['combined_guide_seqs'].str.upper()\n","\n","combined_guide_read_df['non_recombinant'] = combined_guide_read_df['uppercase_combined_guide_seqs'].isin(uppercase_reference_list)\n","\n","try:\n","    on_target = combined_guide_read_df['non_recombinant'].value_counts()[1]\n","except KeyError:\n","    print(\"WARNING: There are no on-target hits. Something is probably wrong.\")\n","    on_target = 0\n","try:  \n","    recombinant = combined_guide_read_df['non_recombinant'].value_counts()[0]\n","except KeyError:\n","    print(\"WARNING: There are no recombinant hits. Something is probably wrong.\")\n","    recombinant = 0\n","total_reads = on_target + recombinant\n","on_target_pcnt = (on_target/total_reads)*100\n","recombinant_pcnt = (recombinant/total_reads)*100\n","\n","print(\"#\"*46)\n","print(f\"There are a total of {total_reads} potential read groups after filtering, of these {on_target_pcnt} % were on target for R1 and R2. This means {recombinant_pcnt} % are recombinant read groups.\")\n","print(\"#\"*46)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h94F1qd6Oed0","outputId":"908e2a87-926a-444a-8655-dc8e0849fad1"},"outputs":[{"data":{"text/plain":["read_group    object\n","dtype: object"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["combined_guide_read_df[['read_group']].dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_f6fdRjgn890"},"outputs":[],"source":["# Split data into recombinant and hit subsets.\n","\n","hits_df = combined_guide_read_df[combined_guide_read_df['non_recombinant'] == True][['read_group']]\n","recombinant_df = combined_guide_read_df[combined_guide_read_df['non_recombinant'] == False][['read_group']]\n","\n","hits_list = hits_df.read_group.tolist()\n","\n","r1_reduced_df['hit'] = r1_reduced_df['read_group'].isin(hits_list)\n","r2_reduced_df['hit'] = r2_reduced_df['read_group'].isin(hits_list)\n","\n","r1_hits_df = r1_reduced_df[r1_reduced_df['hit'] == True]\n","r1_recombinant_df = r1_reduced_df[r1_reduced_df['hit'] == False]\n","\n","r2_hits_df = r2_reduced_df[r2_reduced_df['hit'] == True]\n","r2_recombinant_df = r2_reduced_df[r2_reduced_df['hit'] == False]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1xHt9aBh22sW"},"source":["# 5. Export 'hits.\\*' and 'recombinants.\\*' per fastq.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZkAlRbp01GRd"},"outputs":[],"source":["# Now its just back to the fastqs from here ... ouch. Start stacking the hits!\n","\n","r1_hits_stacked_df = r1_hits_df[['title', 'seq', 'plus', 'qual']].stack()\n","r2_hits_stacked_df = r2_hits_df[['title', 'seq', 'plus', 'qual']].stack()\n","\n","r1_hits_fastq_df = r1_hits_stacked_df\n","r2_hits_fastq_df = r2_hits_stacked_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCvO8Gm0Oz63","outputId":"53b52e3e-9498-4e9b-fdbf-4eb5750a961b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n"]}],"source":["# Identify fails, these are recombinants with either R1 or R2 not in the guide list. If the uppercase guide sequences are not in a match to uppercase r1_key or r2_key from guides_df.\n","uppercase_r1_keys = [x.upper() for x in guides_df['r1_key']]\n","uppercase_r2_keys = [x.upper() for x in guides_df['r2_key']]\n","\n","r1_recombinant_df['uppercase_guide_seq'] = [x.upper() for x in r1_recombinant_df['guide_seq']]\n","r2_recombinant_df['uppercase_guide_seq'] = [x.upper() for x in r2_recombinant_df['guide_seq']]\n","\n","r1_recombinant_df['in_guide_library'] = r1_recombinant_df['uppercase_guide_seq'].isin(uppercase_r1_keys)\n","r2_recombinant_df['in_guide_library'] = r2_recombinant_df['uppercase_guide_seq'].isin(uppercase_r2_keys)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Lwc31hKTX0U","outputId":"ff6bf7cf-2c84-45a8-ba78-a6a3740783c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["##############################################\n","Of the 3763 recombinant read groups, 470 read groups had a sequence not inthe guide list, so 12.490034546904067 % of recombinants can be considered failures.\n","##############################################\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n"]}],"source":["# Split R1 and R2 into true recombinants and failed recombinants based on the 'in_guide_library' flag. But first make a list of read groups that fail. Then pull these readgroups to split true recombinants and fails.\n","r1_failed_recombinants = r1_recombinant_df[r1_recombinant_df['in_guide_library'] == False]\n","r2_failed_recombinants = r2_recombinant_df[r2_recombinant_df['in_guide_library'] == False]\n","\n","recombinant_failed_readgroups = r1_failed_recombinants['read_group'].append(r1_failed_recombinants['read_group']).unique()\n","N_big_fails = len(recombinant_failed_readgroups)\n","\n","r1_recombinant_df['big_fail'] = r1_recombinant_df['read_group'].isin(recombinant_failed_readgroups)\n","r2_recombinant_df['big_fail'] = r2_recombinant_df['read_group'].isin(recombinant_failed_readgroups)\n","\n","r1_failed_recombinants_df = r1_recombinant_df[r1_recombinant_df['big_fail'] == True]\n","r2_failed_recombinants_df = r2_recombinant_df[r2_recombinant_df['big_fail'] == True]\n","r1_true_recombinants_df = r1_recombinant_df[r1_recombinant_df['big_fail'] == False]\n","r2_true_recombinants_df = r2_recombinant_df[r2_recombinant_df['big_fail'] == False]\n","\n","big_fail_pcnt = (N_big_fails/recombinant)*100\n","\n","print(\"#\"*46)\n","print(f\"Of the {recombinant} recombinant read groups, {N_big_fails} read groups had a sequence not inthe guide list, so {big_fail_pcnt} % of recombinants can be considered failures.\")\n","print(\"#\"*46)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hWzsfz4_O0EI"},"outputs":[],"source":["#new lines: swap sequences\n","def swap_r1_r2_seq(r2_sequence):\n","    row = guides_df[guides_df['r2_key'] == r2_sequence[0:19].upper()]\n","    return row.iloc[0]['r1_key']\n","# Start stacking the recombinants!\n","r1_failed_recombinant_stacked_df = r1_failed_recombinants_df[['title', 'seq', 'plus', 'qual']].stack()\n","r2_failed_recombinant_stacked_df = r2_failed_recombinants_df[['title', 'seq', 'plus', 'qual']].stack()\n","\n","r1_failed_recombinant_fastq_df = r1_failed_recombinant_stacked_df\n","r2_failed_recombinant_fastq_df = r2_failed_recombinant_stacked_df\n","\n","r1_true_recombinant_stacked_df = r1_true_recombinants_df[['title', 'seq', 'plus', 'qual']].stack()\n","#new line below\n","r2_true_recombinants_df['seq'] = r2_true_recombinants_df['seq'].map(lambda x: swap_r1_r2_seq(x))\n","r2_true_recombinant_stacked_df = r2_true_recombinants_df[['title', 'seq', 'plus', 'qual']].stack()\n","\n","r1_true_recombinant_fastq_df = r1_true_recombinant_stacked_df\n","r2_true_recombinant_fastq_df = r2_true_recombinant_stacked_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uE0r61FP1GXP"},"outputs":[],"source":["# Export the new fastq.\n","\n","r1_hits_out_file = \"hits.\" + r1_file\n","r2_hits_out_file = \"hits.\" + r2_file\n","\n","r1_hits_fastq_df.to_csv(r1_hits_out_file, sep='\\t', index=False, header=False, compression='gzip')\n","r2_hits_fastq_df.to_csv(r2_hits_out_file, sep='\\t', index=False, header=False, compression='gzip')\n","\n","r1_true_recombinant_out_file = \"recombinants.\" + r1_file\n","r2_true_recombinant_out_file = \"recombinants.\" + r2_file\n","\n","r1_true_recombinant_fastq_df.to_csv(r1_true_recombinant_out_file, sep='\\t', index=False, header=False, compression='gzip')\n","r2_true_recombinant_fastq_df.to_csv(r2_true_recombinant_out_file, sep='\\t', index=False, header=False, compression='gzip')\n","\n","r1_failed_recombinant_out_file = \"fails.\" + r1_file\n","r2_failed_recombinant_out_file = \"fails.\" + r2_file\n","\n","r1_failed_recombinant_fastq_df.to_csv(r1_failed_recombinant_out_file, sep='\\t', index=False, header=False, compression='gzip')\n","r2_failed_recombinant_fastq_df.to_csv(r2_failed_recombinant_out_file, sep='\\t', index=False, header=False, compression='gzip')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pSnDDeBFwldN"},"source":["# Add some narrative.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"laohoOPHwrpc","outputId":"5b972963-62f7-4593-ec7c-46ddd042e7f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["##############################################\n","Your analysis has just finished.\n","Reads from matched read groups on whose guides were on target for both R1 and R2 are found in the files prefixed hits.*.\n","Reads from matched read groups on whose guides were on were off target and considered recombinant for either R1 and R2 are found in the files prefixed recombinants.*.\n","Reads from recombinant read groups on whose guides were not mathced to a known guide sequence for either R1 and R2 are found in the files prefixed fails.*.\n","Good luck and feel free to generally ignore any outputs below here!\n","##############################################\n"]}],"source":["print(\"#\"*46)\n","print(\"Your analysis has just finished.\")\n","print(\"Reads from matched read groups on whose guides were on target for both R1 and R2 are found in the files prefixed hits.*.\")\n","print(\"Reads from matched read groups on whose guides were on were off target and considered recombinant for either R1 and R2 are found in the files prefixed recombinants.*.\")\n","print(\"Reads from recombinant read groups on whose guides were not mathced to a known guide sequence for either R1 and R2 are found in the files prefixed fails.*.\")\n","print(\"Good luck and feel free to generally ignore any outputs below here!\")\n","print(\"#\"*46)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"e5BHGkCOsNFm"},"source":["# Just for executable testing below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aqIujLxKUkI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGTQX4_EKX8Q"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMdX9HSlsMCC","outputId":"f6ae539c-cb53-4af3-b2d1-a1346c38ae23"},"outputs":[{"name":"stdout","output_type":"stream","text":["##############################################\n","Thanks for trying the dual_guide_parser from CARD + iNDI + DTi.\n","To run this code, you will need to specify the guides_file, this is a file similar to the example 20200513_library_1_2_unbalanced_dJR051.csv.\n","You will need to specify a pair of R1 and R2 files, such as UDP0007_S1_R1_001.fastq.gz and UDP0007_S1_R2_001.fastq.gz.\n","You can also specify the number of read groups you are interested for testing the tool, this relates to the option n_groups. This will only read that many readgroups from the R1 and R2 files, allowing you to speed things up a bit.\n","This code must be run from the working directory that contains the R1 and R2 files, but the guides_file can be anywhere, just specify a full path to the guides file like ~/Desktop/20200513_library_1_2_unbalanced_dJR051.csv.\n","This is best run on a large RAM / high CPU set up as the files are quite large.\n","##############################################\n","##############################################\n","\n","Here is some basic info on the command you are about to run.\n","Python version info...\n","3.7.11 (default, Jul  3 2021, 18:01:19) \n","[GCC 7.5.0]\n","CLI argument info...\n","The guides file you are using is 20200513_library_1_2_unbalanced_dJR051.csv .\n","The r1 file you are using is UDP0007_S1_R1_001.fastq.gz .\n","The r2 file you are using is UDP0007_S1_R2_001.fastq.gz .\n","How many read groups are only for a quick test and not the full set? 100000 .\n","\n","##############################################\n","##############################################\n","R1 had 100000 potential read groups, of these 100.0 % were among the concensus read groups. R2 had 100000 potential read groups, of these 100.0 % were among the concensus read groups. In total there are 100000 read groups that are matching across R1 and R2 for this experiment.\n","##############################################\n","##############################################\n","There are a total of 100000 potential read groups after filtering, of these 61.42999999999999 % were on target for R1 and R2. This means 38.57 % are recombinant read groups.\n","##############################################\n","##############################################\n","Of the 38570 recombinant read groups, 4988 read groups had a sequence not inthe guide list, so 12.93233082706767 % of recombinants can be considered faiures.\n","##############################################\n","##############################################\n","Your analysis has just finished.\n","Reads from matched read groups on whose guides were on target for both R1 and R2 are found in the files prefixed hits.*.\n","Reads from matched read groups on whose guides were on were off target and considered recombinant for either R1 and R2 are found in the files prefixed recombinants.*.\n","Reads from recombinant read groups on whose guides were not mathced to a known guide sequence for either R1 and R2 are found in the files prefixed fails.*.\n","Good luck and feel free to generally ignore any outputs below here!\n","##############################################\n"]},{"name":"stderr","output_type":"stream","text":["19bp_dual_guide_parser_tool.py:40: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","19bp_dual_guide_parser_tool.py:150: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  r1_read_groups_df['read_group'] = r1_read_groups_df[\"fastq_content\"].str.split(\" \", n = 1, expand = True)[0]\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n","19bp_dual_guide_parser_tool.py:153: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  r2_read_groups_df['read_group'] = r2_read_groups_df[\"fastq_content\"].str.split(\" \", n = 1, expand = True)[0]\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n","19bp_dual_guide_parser_tool.py:280: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  r1_recombinant_df['uppercase_guide_seq'] = [x.upper() for x in r1_recombinant_df['guide_seq']]\n","19bp_dual_guide_parser_tool.py:281: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  r2_recombinant_df['uppercase_guide_seq'] = [x.upper() for x in r2_recombinant_df['guide_seq']]\n","19bp_dual_guide_parser_tool.py:283: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  r1_recombinant_df['in_guide_library'] = r1_recombinant_df['uppercase_guide_seq'].isin(uppercase_r1_keys)\n","19bp_dual_guide_parser_tool.py:284: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  r2_recombinant_df['in_guide_library'] = r2_recombinant_df['uppercase_guide_seq'].isin(uppercase_r2_keys)\n","19bp_dual_guide_parser_tool.py:293: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  r1_recombinant_df['big_fail'] = r1_recombinant_df['read_group'].isin(recombinant_failed_readgroups)\n","19bp_dual_guide_parser_tool.py:294: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  r2_recombinant_df['big_fail'] = r2_recombinant_df['read_group'].isin(recombinant_failed_readgroups)\n"]}],"source":["%%bash\n","# python 19bp_dual_guide_parser_tool.py --help\n","python 19bp_dual_guide_parser_tool.py --guides_file 20200513_library_1_2_unbalanced_dJR051.csv --r1_file UDP0007_S1_R1_001.fastq.gz --r2_file UDP0007_S1_R2_001.fastq.gz --N_reads 100000"]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"dual_guide_parser_v6.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
